{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modern Portfolio Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modern Portfolio Theory has a number of assumptions which includes\n",
    "\n",
    "* investors are risk averse, meaning that given two portfolios that offer the same expected return, investors will prefer the less risky one. \n",
    "\n",
    "* An investor will take on increased risk only if compensated by higher expected returns. \n",
    "\n",
    "* Conversely, an investor who wants higher expected returns must accept more risk. \n",
    "\n",
    "* The exact trade-off will be the same for all investors, but different investors will evaluate the trade-off differently based on individual risk aversion characteristics. \n",
    "\n",
    "* The implication is that a rational investor will not invest in a portfolio if a second portfolio exists with a more favorable risk-expected return profile â€“ i.e., if for that level of risk an alternative portfolio exists that has better expected returns.\n",
    "\n",
    "* There are 252 trading days in a calendar year on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader as web\n",
    "import scipy.stats as scs\n",
    "import scipy.optimize as sco\n",
    "import statsmodels.api as sm\n",
    "import scipy.interpolate as sci\n",
    "plt.style.use('ggplot')\n",
    "np.random.seed(1479)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normality_tests(arr):\n",
    "    ''' Tests for normality distribution of given data set.\n",
    "    Parameters\n",
    "    ==========\n",
    "    array: ndarray\n",
    "    object to generate statistics on\n",
    "    '''\n",
    "    print('Skew of data set %14.3f' % scs.skew(arr))\n",
    "    print('Skew test p-value %14.3f' % scs.skewtest(arr)[1])\n",
    "    print('Kurt of data set %14.3f' % scs.kurtosis(arr))\n",
    "    print('Kurt test p-value %14.3f' % scs.kurtosistest(arr)[1])\n",
    "    print('Norm test p-value %14.3f' % scs.normaltest(arr)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics(array):\n",
    "    ''' Prints selected statistics.\n",
    "    Parameters\n",
    "    ==========\n",
    "    array: ndarray\n",
    "    object to generate statistics on\n",
    "    '''\n",
    "    sta = scs.describe(array)\n",
    "    print('%14s %15s' % ('statistic', 'value'))\n",
    "    print(30 * '-')\n",
    "    print('%14s %15.5f' % ('size', sta[0]))\n",
    "    print('%14s %15.5f' % ('min', sta[1][0]))\n",
    "    print('%14s %15.5f' % ('max', sta[1][1]))\n",
    "    print('%14s %15.5f' % ('mean', sta[2]))\n",
    "    print('%14s %15.5f' % ('std', np.sqrt(sta[3])))\n",
    "    print('%14s %15.5f' % ('skew', sta[4]))\n",
    "    print('%14s %15.5f' % ('kurtosis', sta[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data as pdr\n",
    "import fix_yahoo_finance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yprices(name, start, end):\n",
    "    '''    \n",
    "        Arguments: \n",
    "            name(string)    : input the ticker for the desired stock\n",
    "            start(datetime) : Setting a starting date\n",
    "            end(datetime)   : Setting a ending date \n",
    "         Returns:\n",
    "            The function returns a Pandas DataFrame webscraped from yahoo finance containing the Date, High, Low, Close, Adj Close and Volume for the inquired stock \n",
    "            More information can be found at https://github.com/ranaroussi/fix-yahoo-finance\n",
    "    '''\n",
    "    yf.pdr_override() # Command to override the pandas search function\n",
    "    return pdr.get_data_yahoo(name, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(weights):\n",
    " weights = np.array(weights)\n",
    " pret = np.sum(rets.mean() * weights) * 252\n",
    " pvol = np.sqrt(np.dot(weights.T, np.dot(rets.cov() * 252, weights)))\n",
    " return np.array([pret, pvol, pret / pvol])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_func_sharpe(weights):\n",
    "     return -statistics(weights)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_func_variance(weights):\n",
    "     return statistics(weights)[1] ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_func_port(weights):\n",
    " return statistics(weights)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data collecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = ['AAPL', 'MSFT', 'FB', 'DB', 'GLD']\n",
    "noa = len(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime(2010, 1, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.datetime(2018, 10, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing a webscrape of the yahoo price website for the quoted tickers, and lastly looking at the head and tail of the dataframe to ensure that we have the data needed for making the analysis and ensuring that we can optimize the porfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "[*********************100%***********************]  1 of 1 downloaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>FB</th>\n",
       "      <th>DB</th>\n",
       "      <th>GLD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-27</th>\n",
       "      <td>19.802147</td>\n",
       "      <td>23.597769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.200840</td>\n",
       "      <td>106.529999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-28</th>\n",
       "      <td>18.983883</td>\n",
       "      <td>23.192135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.284924</td>\n",
       "      <td>106.480003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-29</th>\n",
       "      <td>18.295170</td>\n",
       "      <td>22.412704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.859688</td>\n",
       "      <td>105.959999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-01</th>\n",
       "      <td>18.549507</td>\n",
       "      <td>22.595629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.887768</td>\n",
       "      <td>108.349998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-27</th>\n",
       "      <td>223.210526</td>\n",
       "      <td>113.433426</td>\n",
       "      <td>168.839996</td>\n",
       "      <td>11.810000</td>\n",
       "      <td>112.050003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-28</th>\n",
       "      <td>223.994431</td>\n",
       "      <td>113.393768</td>\n",
       "      <td>164.460007</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>112.760002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-01</th>\n",
       "      <td>225.502670</td>\n",
       "      <td>114.623184</td>\n",
       "      <td>162.440002</td>\n",
       "      <td>11.250000</td>\n",
       "      <td>112.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-02</th>\n",
       "      <td>227.507050</td>\n",
       "      <td>114.167114</td>\n",
       "      <td>159.330002</td>\n",
       "      <td>11.130000</td>\n",
       "      <td>113.870003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AAPL        MSFT          FB         DB         GLD\n",
       "Date                                                                 \n",
       "2010-01-27   19.802147   23.597769         NaN  51.200840  106.529999\n",
       "2010-01-28   18.983883   23.192135         NaN  50.284924  106.480003\n",
       "2010-01-29   18.295170   22.412704         NaN  49.859688  105.959999\n",
       "2010-02-01   18.549507   22.595629         NaN  51.887768  108.349998\n",
       "2018-09-27  223.210526  113.433426  168.839996  11.810000  112.050003\n",
       "2018-09-28  223.994431  113.393768  164.460007  11.360000  112.760002\n",
       "2018-10-01  225.502670  114.623184  162.440002  11.250000  112.570000\n",
       "2018-10-02  227.507050  114.167114  159.330002  11.130000  113.870003"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "for sym in symbols:\n",
    " data[sym] = yprices(sym, start, end)['Adj Close']\n",
    "data.columns = symbols\n",
    "#loop that creates a dataframe\n",
    "data.iloc[np.r_[0:4, -4:0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normal distribution can be considered the most important distribution in\n",
    "finance and one of the major statistical building blocks of financial theory.\n",
    "Among others, the following cornerstones of financial theory rest to a large\n",
    "extent on the assumption that returns of a financial instrument are normally\n",
    "distributed.\n",
    "\n",
    "We see in the first figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(data).plot(figsize=(15, 5))\n",
    "plt.legend(loc='upper left', fontsize=12)\n",
    "plt.ylabel('prices in $')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to plot this is plotting log daily returns (percent change compared to the day before). By plotting daily returns instead of actual prices, we can see the stocksâ€™ volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets = np.log(data / data.shift(1))\n",
    "#new column for returns based on position above\n",
    "#this uses log returns\n",
    "rets.head(2)\n",
    "#checking log returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "for c in rets.columns.values:\n",
    "    plt.plot(rets.index, rets[c], lw=3, alpha=0.8,label=c)\n",
    "plt.legend(loc='upper right', fontsize=12)\n",
    "plt.ylabel('daily returns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon has two distinctive positive spikes and a couple of negative ones. Facebook has one highest positive spike. And Apple also has some spikes stand out from the plot. From the above plot, we can roughly see that Amazon looks like a quite risky stock, and Google seems to be the most stable one among them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Means, covariances and other measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The annual return of the different stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rets.mean() * 252\n",
    "#simple arithmetic mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The annual covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rets.cov()*252"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Portfolio weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weights = np.random.random(noa)\n",
    "#new numpy array of 4 random number that add up to 1\n",
    "weights /= np.sum(weights)\n",
    "#second line assures weight are equal to 1\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected return of i'th portfolio $\\mathbb{E} R_{i}=w_{i, j}^{T} \\times \\mathbb{E} R_{j}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.sum(rets.mean() * weights) * 252"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volatility of i'th portfolio $\\sigma_{i}^{2}=w_{i, j}^{T} \\times \\operatorname{cov}\\left(R_{j}\\right) \\times w_{i, j}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.dot(weights.T, np.dot(rets.cov() * 252, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Deviations of the i'th portfolio $\\sqrt{\\sigma_{i}^{2}=w_{i, j}^{T} \\times \\operatorname{cov}\\left(R_{j}\\right) \\times w_{i, j}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.sqrt(np.dot(weights.T, np.dot(rets.cov() * 252, weights)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prets = []\n",
    "pvols = []\n",
    "#prets and vols are np.arrays\n",
    "for p in range (20000):\n",
    " #loop underlines number of iterations for a random waiting\n",
    " weights = np.random.random(noa)\n",
    " weights /= np.sum(weights)\n",
    " #this makes it equal to 1\n",
    " prets.append(np.sum(rets.mean() * weights) * 252)\n",
    " #i get a value for each loop\n",
    " pvols.append(np.sqrt(np.dot(weights.T, np.dot(rets.cov() * 252, weights))))\n",
    "  #covariance value for each loop\n",
    "\n",
    "prets = np.array(prets)\n",
    "pvols = np.array(pvols)\n",
    "#turns prets and pvols from lists into numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(pvols, prets, c = prets / pvols, marker='o', cmap='coolwarm')\n",
    "# c is a calculated column of a sharpe ratio minus a risk free rate\n",
    "# x-axis, y-axis, marker allows me to change the point style\n",
    "plt.grid(True)\n",
    "plt.xlabel('expected volatility')\n",
    "plt.ylabel('expected return')\n",
    "plt.colorbar(label='Sharpe ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build a function that, for a given vector of portfolio weights $w_i$, it\n",
    "returns the portfolioâ€™s expected return, volatility, and the Sharpe ratio\n",
    "(as a vector).\n",
    "\n",
    "Where the sharpe ratio is defined as the average return earned in excess of the risk-free rate per unit of volatility or total risk\n",
    "\n",
    "\n",
    "$\\textit{Sharpe Ratio}  =\\frac{R_{p}-R_{f}}{\\sigma_{p}}$\n",
    "\n",
    "where\n",
    "\n",
    "$\\begin{aligned} R_{p} &=\\textit { Return of portfolio } \\\\ R_{f} &=\\textit { Risk-free rate } \\\\ \\sigma_{p} &=\\textit { Standard deviation of the portfolio's excess return } \\end{aligned}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(weights):\n",
    " weights = np.array(weights)\n",
    " pret = np.sum(rets.mean() * weights) * 252 # annualized portfolio return\n",
    " pvol = np.sqrt(np.dot(weights.T, np.dot(rets.cov() * 252, weights))) # annualized portfolio variance\n",
    " return np.array([pret, pvol, pret / pvol]) # a tuble of annualized portfolio return, annualized portfolio variance and Sharpe Ratio of the portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the optimization module from Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as sco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for the negative Sharpe ratio\n",
    "(we want to maximise it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_func_sharpe(weights):\n",
    " return -statistics(weights)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the constraint that portfolio weights add up to one $\\sum^{n}_{i=1}w_i=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "#this is a dictionary with two objects, that constrains the optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up boundaries for the portfolio weights (between 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnds = tuple((0, 1) for x in range(noa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Sharpe ratio portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "opts = sco.minimize(min_func_sharpe, noa * [1. / noa,], method='SLSQP', bounds=bnds, constraints=cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing portfolio weights for the optimal sharpe portfolio allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opts['x'].round(2)\n",
    "#creates nparray based on key 'x' from the optimization, and rounds to 3 digit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the expected return, variance and standard deviation from the assets in the portfolio based on their individual weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics(opts['x']).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum Sharpe ratio portfolio properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum variance portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "optv = sco.minimize(min_func_variance, noa * [1. / noa,], method='SLSQP', bounds=bnds,\n",
    "constraints=cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optv['x'].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics(optv['x']).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EFFICIENT FRONTIER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Scipy to minimize the sharpe function\n",
    "\n",
    "$\\min_{w_{i}} w_{i}^{T} \\Sigma w_{i}$\n",
    "\n",
    "s.t\n",
    "\n",
    "$w_{i}^{T} R=R_{\\text { target }}$\n",
    "\n",
    "\n",
    "where portfolio variances is defined as\n",
    "\n",
    " $w^TAw$= $\\begin{bmatrix}w_1 \\cdots w_n\\end{bmatrix} \\cdot \\begin{bmatrix}\n",
    "\\sigma_{n1}^{2}& \\cdots & \\sigma_{1m}^{2}\\\\\n",
    "\\vdots     & \\ddots & \\vdots \\\\\n",
    "\\sigma_{n1}^{2}& \\cdots & \\sigma_{nm}^{2}\\\\\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix} \n",
    "w_1  \\\\\n",
    "\\vdots  \\\\\n",
    "w_n  \\\\\n",
    "\\end{bmatrix}$ \n",
    "\n",
    "\n",
    "\n",
    "* We solve this problem for many levels of the target return.\n",
    "* Each time we do, we get another point on the efficient frontier.\n",
    "* We need to specify the constraint in a loop, as the target return\n",
    "is always changing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons = ({'type': 'eq', 'fun': lambda x: statistics(x)[0] - tret},\n",
    "{'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "bnds = tuple((0, 1) for x in weights)\n",
    "#normal bounds for optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a range for target returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trets = np.linspace(0.0, 0.25, 100)\n",
    "#50 iterations, and the bounds\n",
    "tvols = []\n",
    "for tret in trets:\n",
    " cons = ({'type': 'eq', 'fun': lambda x: statistics(x)[0] - tret}, {'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    " res = sco.minimize(min_func_port, noa * [1. / noa,], method='SLSQP', bounds=bnds, constraints=cons)\n",
    " tvols.append(res['fun'])\n",
    "tvols = np.array(tvols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.scatter(pvols, prets,\n",
    " c=prets / pvols, marker='|', cmap ='coolwarm')\n",
    " # random portfolio composition\n",
    "plt.scatter(tvols, trets,\n",
    " c=trets / tvols, marker='x', cmap='coolwarm')\n",
    " # efficient frontier\n",
    "plt.plot(statistics(opts['x'])[1], statistics(opts['x'])[0],\n",
    " 'r*', markersize=15.0)\n",
    " # portfolio with highest Sharpe ratio\n",
    "plt.plot(statistics(optv['x'])[1], statistics(optv['x'])[0],\n",
    " 'y*', markersize=15.0)\n",
    " # minimum variance portfolio\n",
    "plt.grid(True)\n",
    "plt.xlabel('expected volatility')\n",
    "plt.ylabel('expected return')\n",
    "plt.colorbar(label='Sharpe ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAPITAL MARKET LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.interpolate as sci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trick is to remember that the return vector is sorted in ascending\n",
    "order.\n",
    "Portfolios with returns above the minimum variance portfolio are\n",
    "non-dominated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.argmin(tvols)\n",
    "evols = tvols[ind:]\n",
    "erets = trets[ind:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tck = sci.splrep(evols, erets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "#Efficient frontier function (splines approximation)\n",
    " return sci.splev(x, tck, der=0)\n",
    "def df(x):\n",
    "#First derivative of efficient frontier function\n",
    " return sci.splev(x, tck, der=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{aligned} t(x) &=a+b \\cdot x \\\\ t(0) &=r_{f} \\\\ t(x) &=f(x) \\\\ t(x) &=f(x) & \\Leftrightarrow \\quad b \\end{aligned}=f(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equations(p, rf=0):\n",
    " eq1 = rf - p[0]\n",
    " eq2 = rf + p[1] * p[2] - f(p[2])\n",
    " eq3 = p[1] - df(p[2])\n",
    " return eq1, eq2, eq3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = sco.fsolve(equations, [0.01, 0.5, 0.15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(equations(opt), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.scatter(pvols, prets,\n",
    " c=(prets - 0.01) / pvols, marker='o', cmap='coolwarm')\n",
    " # random portfolio composition\n",
    "plt.plot(evols, erets, 'black', lw=4.0)\n",
    " # efficient frontier\n",
    "cx = np.linspace(0.0, 0.3)\n",
    "plt.plot(cx, opt[0] + opt[1] * cx, lw=1.5)\n",
    " # capital market line\n",
    "plt.plot(opt[2], f(opt[2]), 'r*', markersize=15.0)\n",
    "plt.grid(True)\n",
    "plt.axhline(0, color='k', ls='-', lw=2.0)\n",
    "plt.axvline(0, color='k', ls='-', lw=2.0)\n",
    "plt.xlabel('expected volatility')\n",
    "plt.ylabel('expected return')\n",
    "plt.colorbar(label='Sharpe ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The optimal portfolio allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
